---
layout: publication_page
show: true
noheader: true

title: 'The Stable Signature: Rooting Watermarks in Latent Diffusion Models'
description: 

date: 2023-03-08

authors:
  - name: Pierre Fernandez
    url: "https://pierrefdz.github.io/"
    affiliations: [Meta AI, Inria]
  - name: Guillaume Couairon
    url: "https://scholar.google.com/citations?user=O1DeDyEAAAAJ&hl=en"
    affiliations: [Meta AI]
  - name: Hervé Jégou
    url: "https://scholar.google.com/citations?user=1lcY2z4AAAAJ&hl=en"
    affiliations: [Meta AI]
  - name: Matthijs Douze
    url: "https://scholar.google.com/citations?user=0eFZtREAAAAJ&hl=en"
    affiliations: [Meta AI]
  - name: Teddy Furon
    url: "https://scholar.google.com/citations?hl=en&user=aLUbWzAAAAAJ"
    affiliations: [Inria]

journal: preprint (under review)
bib: /assets/bibliography/stablesignature.txt
pdf: /assets/publis/stablesignature/paper.pdf 
img: /assets/publis/stablesignature/splash.png

header-includes:
  - \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
---

## TL;DR (Summary)

Recent progress in image generation has made it easy to create and manipulate images in a realistic manner with models like DALL·E~2 and Stable Diffusion. 
It raises concerns about responsible deployment of these models.

Stable Signature is a watermarking technique that modifies the generative model such that all images it produces hide an invisible signature.
These signatures can be used to detect and track the origin of images generated by latent diffusion models.

## How does it work?


### Image generation with Latent Diffusion Models

Latent Diffusion Models (LDMs) are generative models that produce images by using diffusion processes in the latent space of a variational auto-encoder (like VQ-GAN).
The diffusion process is guided by a text prompt, which is used to control the generation of latents.
The images are generated by decoding the latents at the end of the diffusion process, with the help of the VAE's decoder.

<img src="/assets/publis/stablesignature/generation.gif" class="img-fluid thumbnail mt-2" alt="LDM generation - overview">

### Stable Signature overview

By fine-tuning the decoder of the VAE, we can slightly modify all generated images, such that they hide an invisible signature.
In our case, Alice fine-tunes the decoder to produce images that hide a 48-bits binary signature. 
As an example use-case, she can later give her signature to content sharing platforms, allowing them to block content generated by her model.

<img src="/assets/publis/stablesignature/stablesign_anim.gif" class="img-fluid thumbnail mt-2" alt="Stable Signature - overview">



### Method


#### Watermark pre-training
First, we train the watermark extractor $$W$$.


#### Fine-tuning the decoder
Then, we fine-tune the decoder $$D$$ of the VAE to produce images that hide the signature $$b$$.


## Results

### Images

Examples of images generated by LDMs from text prompts with and without watermarking with Stable Signature.
Left: we use the default decoder (without watermark fine-tuning).
Middle: we use the decoder fine-tuned with a 48-bits signature.
Right: We show the difference, multiplied by 10 because the distortion is hard to perceive.

<img src="/assets/publis/stablesignature/qual.svg" class="img-fluid thumbnail mt-2" alt="Corgi and T-rex generated with and without watermarked LDMs">







## Links

- [`PDF`]({{page.pdf}})
- [`BibTeX`]({{page.bib}})