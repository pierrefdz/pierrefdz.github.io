---
layout: publication_page
show: false
noheader: true

title: 'Three Bricks to Consolidate Watermarks for Large Language Models'
description: 

date: 2023-07-27

authors:
  - name: Pierre Fernandez
    url: "https://pierrefdz.github.io/"
    affiliations: [Meta AI, Inria]
  - name: Antoine Chaffin
    affiliations: [Imatag, Inria]
  - name: Karim Tit
    affiliations: [Inria]
  - name: Vivien Chappelier
    affiliations: [Imatag]
  - name: Teddy Furon
    url: "https://scholar.google.com/citations?hl=en&user=aLUbWzAAAAAJ"
    affiliations: [Inria]

journal: preprint (under review)
arxiv: https://arxiv.org/abs/TODO
code: https://github.com/pierrefdz/three_bricks
bib: /assets/bibliography/threebricks.txt
pdf: /assets/publis/threebricks/paper.pdf 
img: /assets/publis/threebricks/splash.png

header-includes:
  - \usepackage[ruled,vlined,linesnumbered]{algorithm2e}
---

## TL;DR (Summary)

Three improvements to current watermarking methods for LLMs:
- (1) theoretically grounded and empirically validated statistical tests that guarantee false positive rates,
- (2) evaluation on classical NLP benchmarks,
- (3) extension to scalable multi-bit watermarking

<!-- ## Technical Background -->



## Links

- [`Code`]({{page.code}})
- [`PDF`]({{page.pdf}})
- [`arXiv`]({{page.arxiv}})
- [`BibTeX`]({{page.bib}})
